{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ANALITIKA DATA: EXPLORATORY DATA ANALYSIS\n",
        "\n",
        "disusun oleh:\n",
        "- Dr.Eng.Farrikh Alzami, M.Kom\n",
        "- Ika Novita Dewi, MCs\n",
        "\n",
        "**Universitas Dian Nuswantoro**\n",
        "\n",
        "#Bank Marketing Campaign Dataset\n",
        "\n",
        "**Mata Kuliah**: Analitika Data\n",
        "\n",
        "**Dataset**: Bank Marketing (UCI ML Repository)\n",
        "\n",
        "**Tujuan**: Memahami faktor-faktor yang mempengaruhi keputusan nasabah untuk subscribe term deposit\n",
        "\n",
        "**keterangan**: pakai yang full-additional\n",
        "\n",
        "**link dataset**: https://archive.ics.uci.edu/dataset/222/bank+marketing\n",
        "\n",
        "\n",
        "---\n",
        "##ðŸ“š Learning Outcomes:\n",
        "1. Mampu melakukan eksplorasi dan visualisasi data secara deskriptif\n",
        "2. Mampu melakukan pembersihan dan transformasi data\n",
        "3. Mampu menyusun insight dan storytelling berbasis data\n",
        "4. Mempersiapkan data untuk pemodelan machine learning\n",
        "\n",
        "---\n",
        "##ðŸ“ Struktur Tutorial:\n",
        "- **PERTEMUAN 1**: Foundation (Setup, Loading, Cleaning, Basic Stats)\n",
        "- **PERTEMUAN 2**: Deep Exploration (Univariate, Bivariate, Multivariate)\n",
        "- **PERTEMUAN 3**: Insights & Preparation (Feature Engineering, Storytelling, Export)\n",
        "\n"
      ],
      "metadata": {
        "id": "UI_3H6xyK7UD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # SETUP & INITIALIZATION"
      ],
      "metadata": {
        "id": "qbC80pVcLNbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "B_iRxIr5LeEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrQRGAwLKiw7"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Konfigurasi\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set display options untuk pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load google Drive\n"
      ],
      "metadata": {
        "id": "dM4YCIsDLowN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/')"
      ],
      "metadata": {
        "id": "loe9otFfLqvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDUn4_4PNVVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BASE_PATH = '/content/drive/MyDrive/Colab Notebooks/0 1 analitika data/'  # Path base untuk Drive\n",
        "FIGURES_PATH = BASE_PATH + 'figures/'"
      ],
      "metadata": {
        "id": "U9vh4HFgNRH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory untuk menyimpan figures\n",
        "if not os.path.exists(FIGURES_PATH):\n",
        "    os.makedirs(FIGURES_PATH)\n",
        "\n",
        "print(\"Setup completed successfully!\")\n",
        "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Save path: {FIGURES_PATH}\")"
      ],
      "metadata": {
        "id": "LDeBVWPpNjMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ====================================================================\n",
        "\n",
        "def save_figure(filename):\n",
        "    \"\"\"Helper function to save figures with correct path\"\"\"\n",
        "    plt.savefig(FIGURES_PATH + filename, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def save_csv(df, filename):\n",
        "    \"\"\"Helper function to save CSV with correct path\"\"\"\n",
        "    df.to_csv(FIGURES_PATH + filename, index=False)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def save_text(text, filename):\n",
        "    \"\"\"Helper function to save text file with correct path\"\"\"\n",
        "    with open(FIGURES_PATH + filename, 'w') as f:\n",
        "        f.write(text)\n",
        "    print(f\"Saved: {filename}\")"
      ],
      "metadata": {
        "id": "tJd3qtNdNrfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.1 DATA LOADING & OVERVIEW\n",
        "\n",
        "Dataset Bank Marketing berisi informasi tentang kampanye marketing langsung dari institusi perbankan Portugal.\n",
        "\n",
        "**Konteks Bisnis**:\n",
        "- Bank ingin meningkatkan jumlah nasabah yang subscribe term deposit\n",
        "- Marketing dilakukan via telepon\n",
        "- Perlu identifikasi karakteristik nasabah yang potensial\n",
        "\n",
        "**Download Dataset**:\n",
        "- Source: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
        "- Atau Kaggle: https://www.kaggle.com/datasets/henriqueyamahata/bank-marketing\n",
        "- File: bank-additional-full.csv (atau bank.csv)"
      ],
      "metadata": {
        "id": "akUL_ZXHOXHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = BASE_PATH + 'bank-additional-full.csv'"
      ],
      "metadata": {
        "id": "rxCu2VpdOy1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path, sep=';')"
      ],
      "metadata": {
        "id": "FHCokpU_LRgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick overview\n",
        "print(\"=\"*70)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nDimensi Dataset: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
        "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Tampilkan 5 baris pertama\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NWSialuPO6Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informasi struktur data\n",
        "print(\"\\nINFORMASI KOLOM:\")\n",
        "print(\"=\"*70)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "m2g09ukNPEeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Penjelasan Variabel\n",
        "\n",
        "**Variabel Input - Data Client:**\n",
        "\n",
        "1. `age`: Usia nasabah (numerik)\n",
        "2. `job`: Jenis pekerjaan (kategorikal)\n",
        "3. `marital`: Status pernikahan (kategorikal)\n",
        "4. `education`: Tingkat pendidikan (kategorikal)\n",
        "5. `default`: Apakah memiliki kredit default? (kategorikal)\n",
        "6. `housing`: Apakah memiliki kredit rumah? (kategorikal)\n",
        "7. `loan`: Apakah memiliki kredit personal? (kategorikal)\n",
        "\n",
        "**Variabel Input - Kampanye Saat Ini:**\n",
        "\n",
        "8. `contact`: Tipe komunikasi kontak (kategorikal)\n",
        "9. `month`: Bulan kontak terakhir (kategorikal)\n",
        "10. `day_of_week`: Hari kontak terakhir (kategorikal)\n",
        "11. `duration`: Durasi kontak terakhir dalam detik (numerik)\n",
        "\n",
        "**Variabel Input - Atribut Lain:**\n",
        "\n",
        "12. `campaign`: Jumlah kontak selama kampanye ini (numerik)\n",
        "13. `pdays`: Jumlah hari sejak kontak terakhir dari kampanye sebelumnya (numerik)\n",
        "14. `previous`: Jumlah kontak sebelum kampanye ini (numerik)\n",
        "15. `poutcome`: Outcome dari kampanye marketing sebelumnya (kategorikal)\n",
        "\n",
        "**Variabel Input - Sosial & Ekonomi:**\n",
        "\n",
        "16. `emp.var.rate`: Employment variation rate (numerik)\n",
        "17. `cons.price.idx`: Consumer price index (numerik)\n",
        "18. `cons.conf.idx`: Consumer confidence index (numerik)\n",
        "19. `euribor3m`: Euribor 3 month rate (numerik)\n",
        "20. `nr.employed`: Number of employees (numerik)\n",
        "\n",
        "**Variabel Output (Target):**\n",
        "\n",
        "21. `y`: Apakah client subscribe term deposit? (binary: yes/no)"
      ],
      "metadata": {
        "id": "gc4bz_VnPTnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2 DATA QUALITY ASSESSMENT\n",
        "\n",
        "Sebelum analisis, kita perlu memastikan kualitas data:\n",
        "- Missing values\n",
        "- Duplicate rows\n",
        "- Data types\n",
        "- Outliers potensial\n",
        "- Konsistensi data\n"
      ],
      "metadata": {
        "id": "9eltmps_Pi73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek missing values\n",
        "print(\"\\nðŸ” MISSING VALUES ANALYSIS:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = 100 * missing / len(df)\n",
        "missing_table = pd.DataFrame({\n",
        "    'Missing_Count': missing,\n",
        "    'Percentage': missing_pct\n",
        "})\n",
        "missing_table = missing_table[missing_table['Missing_Count'] > 0].sort_values(\n",
        "    'Percentage', ascending=False\n",
        ")\n",
        "\n",
        "if len(missing_table) > 0:\n",
        "    print(missing_table)\n",
        "else:\n",
        "    print(\"Tidak ada missing values!\")"
      ],
      "metadata": {
        "id": "mlENl4_oPLVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek duplicate rows\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"\\nDUPLICATE ROWS: {duplicates}\")\n",
        "\n",
        "if duplicates > 0:\n",
        "    print(f\"Ditemukan {duplicates} baris duplikat ({100*duplicates/len(df):.2f}%)\")\n",
        "else:\n",
        "    print(\"Tidak ada baris duplikat!\")\n"
      ],
      "metadata": {
        "id": "-UQXOruXPlt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek tipe data dan unique values\n",
        "print(\"\\nDATA TYPES & UNIQUE VALUES:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "data_overview = pd.DataFrame({\n",
        "    'Column': df.columns,\n",
        "    'Type': df.dtypes,\n",
        "    'Unique': [df[col].nunique() for col in df.columns],\n",
        "    'Sample_Values': [df[col].unique()[:3] for col in df.columns]\n",
        "})\n",
        "\n",
        "print(data_overview.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "zfFnsfSMPsuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan variabel numerik dan kategorikal\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Remove target dari list jika ada\n",
        "if 'y' in numerical_cols:\n",
        "    numerical_cols.remove('y')\n",
        "if 'y' in categorical_cols:\n",
        "    categorical_cols.remove('y')\n",
        "\n",
        "print(f\"\\nVariabel Numerik ({len(numerical_cols)}): {numerical_cols}\")\n",
        "print(f\"Variabel Kategorikal ({len(categorical_cols)}): {categorical_cols}\")\n",
        "print(f\"Target Variable: y\")"
      ],
      "metadata": {
        "id": "CywjwTRnPv3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.3 DATA CLEANING & TRANSFORMATION\n",
        "\n",
        "**Konsep Penting:**\n",
        "- **Unknown values**: Beberapa kolom kategorikal punya nilai \"unknown\"\n",
        "- **Pdays = 999**: Artinya client tidak pernah dikontak sebelumnya\n",
        "- **Data consistency**: Pastikan format data konsisten\n"
      ],
      "metadata": {
        "id": "bjKh6pz2P75j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek nilai \"unknown\" di kolom kategorikal\n",
        "print(\"\\n'UNKNOWN' VALUES IN CATEGORICAL COLUMNS:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    unknown_count = (df[col] == 'unknown').sum()\n",
        "    if unknown_count > 0:\n",
        "        unknown_pct = 100 * unknown_count / len(df)\n",
        "        print(f\"{col:20s}: {unknown_count:6d} ({unknown_pct:5.2f}%)\")"
      ],
      "metadata": {
        "id": "PTrwLsPtP2yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle pdays: 999 berarti tidak pernah dikontak\n",
        "# Kita buat feature baru yang lebih interpretable\n",
        "df['was_contacted_before'] = (df['pdays'] != 999).astype(int)\n",
        "\n",
        "print(\"\\nFeature engineering: 'was_contacted_before' created\")\n",
        "print(f\"   - Was contacted before: {df['was_contacted_before'].sum()} ({100*df['was_contacted_before'].mean():.2f}%)\")\n",
        "print(f\"   - Never contacted: {(~df['was_contacted_before'].astype(bool)).sum()} ({100*(1-df['was_contacted_before'].mean()):.2f}%)\")\n"
      ],
      "metadata": {
        "id": "D_1uXKYDQEZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create backup of original data\n",
        "df_original = df.copy()\n",
        "print(\"\\nBackup data original disimpan di 'df_original'\")\n"
      ],
      "metadata": {
        "id": "wvNXZLLAQT1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.4 DESCRIPTIVE STATISTICS\n",
        "\n",
        "**Statistik Deskriptif** memberikan ringkasan tentang pusat dan penyebaran data.\n",
        "\n",
        "**Key Metrics:**\n",
        "- **Mean (rata-rata)**: Nilai tengah, sensitif terhadap outlier\n",
        "- **Median**: Nilai tengah yang membagi data jadi 2 bagian sama\n",
        "- **Std (standar deviasi)**: Ukuran penyebaran data\n",
        "- **Min/Max**: Nilai minimum dan maksimum\n",
        "- **Quartiles (25%, 50%, 75%)**: Membagi data jadi 4 bagian sama\n"
      ],
      "metadata": {
        "id": "8boMsKErQeQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics untuk variabel numerik\n",
        "print(\"\\nDESCRIPTIVE STATISTICS - NUMERICAL VARIABLES:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "desc_stats = df[numerical_cols].describe().T\n",
        "desc_stats['skewness'] = df[numerical_cols].skew()\n",
        "desc_stats['kurtosis'] = df[numerical_cols].kurtosis()\n",
        "\n",
        "print(desc_stats)\n",
        "\n",
        "# Save to CSV for report\n",
        "desc_stats.to_csv(FIGURES_PATH + 'descriptive_stats_numerical.csv')\n",
        "print(\"\\nSaved: descriptive_stats_numerical.csv\")\n"
      ],
      "metadata": {
        "id": "sIjpoay6QYUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretasi Skewness & Kurtosis:\n",
        "\n",
        "**Skewness (Kemiringan)**:\n",
        "- **Skew = 0**: Distribusi simetris (normal)\n",
        "- **Skew > 0**: Right-skewed (ekor panjang ke kanan), lebih banyak nilai kecil\n",
        "- **Skew < 0**: Left-skewed (ekor panjang ke kiri), lebih banyak nilai besar\n",
        "- **|Skew| > 1**: Highly skewed\n",
        "\n",
        "**Kurtosis (Keruncingan)**:\n",
        "- **Kurt = 0**: Normal distribution\n",
        "- **Kurt > 0**: Heavy tails (lebih banyak outliers)\n",
        "- **Kurt < 0**: Light tails (lebih sedikit outliers)\n"
      ],
      "metadata": {
        "id": "XXlMHiwqQnKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics untuk variabel kategorikal\n",
        "print(\"\\nDESCRIPTIVE STATISTICS - CATEGORICAL VARIABLES:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "cat_summary = []\n",
        "for col in categorical_cols:\n",
        "    unique_count = df[col].nunique()\n",
        "    most_common = df[col].mode()[0]\n",
        "    most_common_pct = 100 * (df[col] == most_common).sum() / len(df)\n",
        "\n",
        "    cat_summary.append({\n",
        "        'Variable': col,\n",
        "        'Unique_Values': unique_count,\n",
        "        'Most_Common': most_common,\n",
        "        'Most_Common_Pct': f\"{most_common_pct:.2f}%\"\n",
        "    })\n",
        "\n",
        "cat_summary_df = pd.DataFrame(cat_summary)\n",
        "print(cat_summary_df.to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "cat_summary_df.to_csv(FIGURES_PATH + 'descriptive_stats_categorical.csv', index=False)\n",
        "print(\"\\nSaved: descriptive_stats_categorical.csv\")\n"
      ],
      "metadata": {
        "id": "aL_AFhndQhbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target variable distribution\n",
        "print(\"\\nTARGET VARIABLE DISTRIBUTION:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "target_dist = df['y'].value_counts()\n",
        "target_dist_pct = 100 * df['y'].value_counts(normalize=True)\n",
        "\n",
        "target_summary = pd.DataFrame({\n",
        "    'Class': target_dist.index,\n",
        "    'Count': target_dist.values,\n",
        "    'Percentage': target_dist_pct.values\n",
        "})\n",
        "\n",
        "print(target_summary.to_string(index=False))\n",
        "\n",
        "# Visualize target distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Count plot\n",
        "target_dist.plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4'])\n",
        "axes[0].set_title('Target Variable Distribution (Count)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Subscribed Term Deposit?')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_xticklabels(['No', 'Yes'], rotation=0)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate(target_dist.values):\n",
        "    axes[0].text(i, v + 500, str(v), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Percentage plot\n",
        "target_dist_pct.plot(kind='bar', ax=axes[1], color=['#FF6B6B', '#4ECDC4'])\n",
        "axes[1].set_title('Target Variable Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Subscribed Term Deposit?')\n",
        "axes[1].set_ylabel('Percentage (%)')\n",
        "axes[1].set_xticklabels(['No', 'Yes'], rotation=0)\n",
        "\n",
        "# Add percentage labels\n",
        "for i, v in enumerate(target_dist_pct.values):\n",
        "    axes[1].text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH + '01_target_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSaved: 01_target_distribution.png\")\n"
      ],
      "metadata": {
        "id": "ijyFOAphQtTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ðŸ’¡ Key Insight #1: Class Imbalance\n",
        "\n",
        "Dataset ini memiliki **class imbalance** yang signifikan. Mayoritas nasabah tidak subscribe term deposit.\n",
        "Ini adalah **masalah klasifikasi yang imbalanced**, perlu diperhatikan saat modeling nanti.\n"
      ],
      "metadata": {
        "id": "8AtHmRMIQ8mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "ðŸ”¬ PERTEMUAN 2: DEEP EXPLORATION\n",
        "---"
      ],
      "metadata": {
        "id": "c31HETy5RE_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.1 UNIVARIATE ANALYSIS - NUMERICAL VARIABLES\n",
        "\n",
        "**Univariate Analysis** = analisis satu variabel pada satu waktu.\n",
        "\n",
        "**Tujuan:**\n",
        "- Memahami distribusi setiap variabel\n",
        "- Identifikasi outliers\n",
        "- Memahami range dan variabilitas data\n"
      ],
      "metadata": {
        "id": "QbC8cAMiRNkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribusi variabel numerik dengan histogram\n",
        "fig, axes = plt.subplots(5, 3, figsize=(18, 20))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(numerical_cols):\n",
        "    # Histogram dengan KDE (Kernel Density Estimation)\n",
        "    axes[idx].hist(df[col], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "    axes[idx].axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[col].mean():.2f}')\n",
        "    axes[idx].axvline(df[col].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[col].median():.2f}')\n",
        "\n",
        "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel(col)\n",
        "    axes[idx].set_ylabel('Frequency')\n",
        "    axes[idx].legend()\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "# Remove empty subplots\n",
        "for idx in range(len(numerical_cols), len(axes)):\n",
        "    fig.delaxes(axes[idx])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH + '02_numerical_distributions.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 02_numerical_distributions.png\")"
      ],
      "metadata": {
        "id": "qU2WdDd6QzwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cara Membaca Distribusi:\n",
        "\n",
        "1. **Bentuk distribusi**:\n",
        "   - **Normal/Bell-shaped**: Data terpusat di sekitar mean\n",
        "   - **Right-skewed**: Banyak nilai kecil, few extreme large values\n",
        "   - **Left-skewed**: Banyak nilai besar, few extreme small values\n",
        "   - **Bimodal**: Ada 2 puncak (mungkin 2 grup berbeda)\n",
        "\n",
        "2. **Mean vs Median**:\n",
        "   - Jika **Mean â‰ˆ Median**: Distribusi simetris\n",
        "   - Jika **Mean > Median**: Right-skewed (outlier besar tarik mean ke kanan)\n",
        "   - Jika **Mean < Median**: Left-skewed"
      ],
      "metadata": {
        "id": "0C8iy2-7RWMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plots untuk deteksi outliers\n",
        "fig, axes = plt.subplots(5, 3, figsize=(18, 20))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(numerical_cols):\n",
        "    bp = axes[idx].boxplot(df[col], vert=True, patch_artist=True)\n",
        "\n",
        "    # Customize box plot\n",
        "    for patch in bp['boxes']:\n",
        "        patch.set_facecolor('lightblue')\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    axes[idx].set_title(f'Box Plot: {col}', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_ylabel(col)\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "    # Add statistics text\n",
        "    q1 = df[col].quantile(0.25)\n",
        "    q3 = df[col].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "    outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
        "\n",
        "    axes[idx].text(0.02, 0.98, f'Outliers: {outliers}',\n",
        "                   transform=axes[idx].transAxes, fontsize=10,\n",
        "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# Remove empty subplots\n",
        "for idx in range(len(numerical_cols), len(axes)):\n",
        "    fig.delaxes(axes[idx])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH + '03_boxplots_outliers.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 03_boxplots_outliers.png\")"
      ],
      "metadata": {
        "id": "JxY8KuOpRRrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cara Membaca Box Plot:\n",
        "\n",
        "**Komponen Box Plot**:\n",
        "- **Box (kotak)**: Berisi 50% data tengah (Q1 to Q3)\n",
        "- **Line in box**: Median (Q2)\n",
        "- **Whiskers (garis)**: Extend sampai 1.5Ã—IQR dari Q1 dan Q3\n",
        "- **Dots/Points**: Outliers (nilai ekstrem di luar whiskers)\n",
        "\n",
        "**IQR (Interquartile Range) = Q3 - Q1**\n",
        "\n",
        "**Outlier Detection Rule**:\n",
        "- Lower bound = Q1 - 1.5Ã—IQR\n",
        "- Upper bound = Q3 + 1.5Ã—IQR\n",
        "- Any value outside bounds = outlier"
      ],
      "metadata": {
        "id": "H-wsaGv4Rjeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung outliers untuk setiap variabel numerik\n",
        "outlier_summary = []\n",
        "\n",
        "for col in numerical_cols:\n",
        "    q1 = df[col].quantile(0.25)\n",
        "    q3 = df[col].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "    outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
        "    outliers_pct = 100 * outliers / len(df)\n",
        "\n",
        "    outlier_summary.append({\n",
        "        'Variable': col,\n",
        "        'Q1': q1,\n",
        "        'Q3': q3,\n",
        "        'IQR': iqr,\n",
        "        'Lower_Bound': lower_bound,\n",
        "        'Upper_Bound': upper_bound,\n",
        "        'Outliers_Count': outliers,\n",
        "        'Outliers_Pct': f\"{outliers_pct:.2f}%\"\n",
        "    })\n",
        "\n",
        "outlier_df = pd.DataFrame(outlier_summary)\n",
        "print(\"\\nOUTLIER DETECTION SUMMARY:\")\n",
        "print(\"=\"*70)\n",
        "print(outlier_df.to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "outlier_df.to_csv(FIGURES_PATH + 'outlier_summary.csv', index=False)\n",
        "print(\"\\nSaved: outlier_summary.csv\")"
      ],
      "metadata": {
        "id": "rLeZq8Y6RZis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.2 UNIVARIATE ANALYSIS - CATEGORICAL VARIABLES\n",
        "\n",
        "Untuk variabel kategorikal, kita lihat:\n",
        "- Distribusi frekuensi setiap kategori\n",
        "- Kategori mana yang dominan\n",
        "- Apakah ada kategori yang jarang muncul\n"
      ],
      "metadata": {
        "id": "Up8tabFgRvc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar plots untuk variabel kategorikal\n",
        "n_categorical = len(categorical_cols)\n",
        "n_rows = (n_categorical + 2) // 3\n",
        "fig, axes = plt.subplots(n_rows, 3, figsize=(18, n_rows * 4))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(categorical_cols):\n",
        "    value_counts = df[col].value_counts()\n",
        "\n",
        "    # Create bar plot\n",
        "    value_counts.plot(kind='bar', ax=axes[idx], color='steelblue', edgecolor='black')\n",
        "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel(col)\n",
        "    axes[idx].set_ylabel('Count')\n",
        "    axes[idx].tick_params(axis='x', rotation=45)\n",
        "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add percentage labels on bars\n",
        "    total = len(df)\n",
        "    for i, v in enumerate(value_counts.values):\n",
        "        pct = 100 * v / total\n",
        "        axes[idx].text(i, v + total*0.01, f'{pct:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Remove empty subplots\n",
        "for idx in range(len(categorical_cols), len(axes)):\n",
        "    fig.delaxes(axes[idx])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH + '04_categorical_distributions.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 04_categorical_distributions.png\")"
      ],
      "metadata": {
        "id": "f404iuMuRpvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed frequency table untuk variabel kategorikal\n",
        "print(\"\\nFREQUENCY TABLES - CATEGORICAL VARIABLES:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col.upper()}:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    freq_table = pd.DataFrame({\n",
        "        'Category': df[col].value_counts().index,\n",
        "        'Count': df[col].value_counts().values,\n",
        "        'Percentage': df[col].value_counts(normalize=True).values * 100\n",
        "    })\n",
        "\n",
        "    print(freq_table.to_string(index=False))\n",
        "\n",
        "    # Save each frequency table\n",
        "    freq_table.to_csv(FIGURES_PATH + f'freq_table_{col}.csv', index=False)\n",
        "\n",
        "print(f\"\\nAll frequency tables saved to '{FIGURES_PATH}'\")"
      ],
      "metadata": {
        "id": "ni7WfyqQRymf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.3 BIVARIATE ANALYSIS - Numerical vs Target\n",
        "\n",
        "**Bivariate Analysis** = analisis hubungan antara 2 variabel.\n",
        "\n",
        "Di sini kita lihat bagaimana variabel numerik berbeda antara:\n",
        "- Nasabah yang subscribe (y=yes)\n",
        "- Nasabah yang tidak subscribe (y=no)"
      ],
      "metadata": {
        "id": "wgpjhG_xSDcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison box plots: Numerical variables vs Target\n",
        "n_numerical = len(numerical_cols)\n",
        "n_rows = (n_numerical + 2) // 3\n",
        "fig, axes = plt.subplots(n_rows, 3, figsize=(18, n_rows * 4))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(numerical_cols):\n",
        "    # Prepare data for each class\n",
        "    data_no = df[df['y'] == 'no'][col]\n",
        "    data_yes = df[df['y'] == 'yes'][col]\n",
        "\n",
        "    # Create box plot\n",
        "    bp = axes[idx].boxplot([data_no, data_yes],\n",
        "                           labels=['No', 'Yes'],\n",
        "                           patch_artist=True,\n",
        "                           showmeans=True)\n",
        "\n",
        "    # Customize colors\n",
        "    colors = ['#FF6B6B', '#4ECDC4']\n",
        "    for patch, color in zip(bp['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    axes[idx].set_title(f'{col} vs Target', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Subscribed?')\n",
        "    axes[idx].set_ylabel(col)\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "    # Add mean values as text\n",
        "    mean_no = data_no.mean()\n",
        "    mean_yes = data_yes.mean()\n",
        "    axes[idx].text(0.02, 0.98, f'Mean (No): {mean_no:.2f}\\nMean (Yes): {mean_yes:.2f}',\n",
        "                   transform=axes[idx].transAxes, fontsize=9,\n",
        "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "# Remove empty subplots\n",
        "for idx in range(len(numerical_cols), len(axes)):\n",
        "    fig.delaxes(axes[idx])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH + '05_numerical_vs_target.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 05_numerical_vs_target.png\")"
      ],
      "metadata": {
        "id": "qnfGEFLGR-ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical tests: T-test untuk membandingkan means\n",
        "# H0: Mean kedua grup sama\n",
        "# H1: Mean kedua grup berbeda\n",
        "# p-value < 0.05 â†’ reject H0 (ada perbedaan signifikan)\n",
        "\n",
        "print(\"\\nT-TEST RESULTS: Numerical Variables vs Target\")\n",
        "print(\"=\"*70)\n",
        "print(\"H0: Tidak ada perbedaan mean antara yes dan no\")\n",
        "print(\"H1: Ada perbedaan mean yang signifikan\")\n",
        "print(\"Significance level (Î±): 0.05\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "ttest_results = []\n",
        "\n",
        "for col in numerical_cols:\n",
        "    data_no = df[df['y'] == 'no'][col]\n",
        "    data_yes = df[df['y'] == 'yes'][col]\n",
        "\n",
        "    # Perform t-test\n",
        "    t_stat, p_value = stats.ttest_ind(data_no, data_yes)\n",
        "\n",
        "    # Calculate effect size (Cohen's d)\n",
        "    mean_diff = data_yes.mean() - data_no.mean()\n",
        "    pooled_std = np.sqrt((data_no.std()**2 + data_yes.std()**2) / 2)\n",
        "    cohens_d = mean_diff / pooled_std\n",
        "\n",
        "    # Interpret results\n",
        "    is_significant = \"Yes\" if p_value < 0.05 else \"No\"\n",
        "\n",
        "    ttest_results.append({\n",
        "        'Variable': col,\n",
        "        'Mean_No': data_no.mean(),\n",
        "        'Mean_Yes': data_yes.mean(),\n",
        "        'Mean_Diff': mean_diff,\n",
        "        'T_Statistic': t_stat,\n",
        "        'P_Value': p_value,\n",
        "        'Significant': is_significant,\n",
        "        'Cohens_d': cohens_d\n",
        "    })\n",
        "\n",
        "ttest_df = pd.DataFrame(ttest_results)\n",
        "print(ttest_df.to_string(index=False))\n",
        "\n",
        "# Save results\n",
        "ttest_df.to_csv(FIGURES_PATH + 'ttest_results.csv', index=False)\n",
        "print(\"\\nSaved: ttest_results.csv\")"
      ],
      "metadata": {
        "id": "XfKEZKQgSG1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretasi T-Test:\n",
        "\n",
        "**P-Value**:\n",
        "- **p < 0.05**: Perbedaan signifikan secara statistik - **p â‰¥ 0.05**: Tidak ada perbedaan signifikan\n",
        "\n",
        "**Cohen's d (Effect Size)**:\n",
        "- **|d| < 0.2**: Small effect\n",
        "- **0.2 â‰¤ |d| < 0.5**: Medium effect\n",
        "- **|d| â‰¥ 0.5**: Large effect\n",
        "- **|d| â‰¥ 0.8**: Very large effect\n",
        "\n",
        "Variabel dengan p-value kecil DAN effect size besar adalah **predictor potensial yang kuat**."
      ],
      "metadata": {
        "id": "SzeySxPTSTLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.4 BIVARIATE ANALYSIS - Categorical vs Target\n",
        "\n",
        "Analisis hubungan antara variabel kategorikal dengan target:\n",
        "- Apakah ada kategori tertentu yang lebih cenderung subscribe?\n",
        "- Chi-square test untuk uji independensi\n"
      ],
      "metadata": {
        "id": "njWGbeVAScl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacked bar plots: Categorical variables vs Target\n",
        "n_categorical = len(categorical_cols)\n",
        "n_rows = (n_categorical + 2) // 3\n",
        "fig, axes = plt.subplots(n_rows, 3, figsize=(18, n_rows * 4))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(categorical_cols):\n",
        "    # Create crosstab (frequency table)\n",
        "    ct = pd.crosstab(df[col], df['y'], normalize='index') * 100\n",
        "\n",
        "    # Create stacked bar plot\n",
        "    ct.plot(kind='bar', stacked=True, ax=axes[idx],\n",
        "            color=['#FF6B6B', '#4ECDC4'], edgecolor='black')\n",
        "\n",
        "    axes[idx].set_title(f'{col} vs Target (Percentage)', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel(col)\n",
        "    axes[idx].set_ylabel('Percentage (%)')\n",
        "    axes[idx].legend(title='Subscribed?', labels=['No', 'Yes'])\n",
        "    axes[idx].tick_params(axis='x', rotation=45)\n",
        "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Remove empty subplots\n",
        "for idx in range(len(categorical_cols), len(axes)):\n",
        "    fig.delaxes(axes[idx])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH + '06_categorical_vs_target.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 06_categorical_vs_target.png\")"
      ],
      "metadata": {
        "id": "sm-BGLVsSMYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chi-square test untuk variabel kategorikal vs target\n",
        "# H0: Variabel independent dari target (tidak ada hubungan)\n",
        "# H1: Variabel dependent (ada hubungan)\n",
        "\n",
        "print(\"\\nCHI-SQUARE TEST RESULTS: Categorical Variables vs Target\")\n",
        "print(\"=\"*70)\n",
        "print(\"H0: Variabel independent dari target (tidak ada hubungan)\")\n",
        "print(\"H1: Variabel dependent dari target (ada hubungan)\")\n",
        "print(\"Significance level (Î±): 0.05\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "chisq_results = []\n",
        "\n",
        "for col in categorical_cols:\n",
        "    # Create contingency table\n",
        "    contingency_table = pd.crosstab(df[col], df['y'])\n",
        "\n",
        "    # Perform chi-square test\n",
        "    chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "    # Calculate CramÃ©r's V (effect size for chi-square)\n",
        "    n = contingency_table.sum().sum()\n",
        "    cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))\n",
        "\n",
        "    # Interpret results\n",
        "    is_significant = \"Yes\" if p_value < 0.05 else \"No\"\n",
        "\n",
        "    chisq_results.append({\n",
        "        'Variable': col,\n",
        "        'Chi2_Statistic': chi2,\n",
        "        'P_Value': p_value,\n",
        "        'Degrees_of_Freedom': dof,\n",
        "        'Significant': is_significant,\n",
        "        'Cramers_V': cramers_v\n",
        "    })\n",
        "\n",
        "chisq_df = pd.DataFrame(chisq_results)\n",
        "print(chisq_df.to_string(index=False))\n",
        "\n",
        "# Save results\n",
        "chisq_df.to_csv(FIGURES_PATH + 'chisquare_results.csv', index=False)\n",
        "print(\"\\nSaved: chisquare_results.csv\")"
      ],
      "metadata": {
        "id": "MGTcotKpSf3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretasi Chi-Square Test:\n",
        "\n",
        "**P-Value**:\n",
        "- **p < 0.05**: Ada hubungan signifikan\n",
        "- **p â‰¥ 0.05**: Tidak ada hubungan signifikan\n",
        "\n",
        "**CramÃ©r's V (Effect Size)**:\n",
        "- **V < 0.1**: Negligible association\n",
        "- **0.1 â‰¤ V < 0.3**: Weak association\n",
        "- **0.3 â‰¤ V < 0.5**: Moderate association\n",
        "- **V â‰¥ 0.5**: Strong association\n",
        "\n",
        "Variabel dengan p-value kecil DAN CramÃ©r's V besar menunjukkan **hubungan yang kuat** dengan target."
      ],
      "metadata": {
        "id": "2Co6Fo5WSqO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.5 MULTIVARIATE ANALYSIS - Correlation Matrix\n",
        "\n",
        "**Correlation** = ukuran kekuatan hubungan linear antara 2 variabel numerik.\n",
        "\n",
        "**Correlation Coefficient (r)**:\n",
        "- **r = 1**: Perfect positive correlation\n",
        "- **r = -1**: Perfect negative correlation\n",
        "- **r = 0**: No linear correlation\n",
        "- **|r| > 0.7**: Strong correlation\n",
        "- **|r| > 0.5**: Moderate correlation\n",
        "- **|r| > 0.3**: Weak correlation"
      ],
      "metadata": {
        "id": "1fWe_F3tSvOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix untuk variabel numerik\n",
        "corr_matrix = df[numerical_cols].corr()\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize=(14, 12))\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Mask upper triangle\n",
        "\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f',\n",
        "            cmap='coolwarm', center=0, square=True,\n",
        "            linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "\n",
        "plt.title('Correlation Matrix - Numerical Variables', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH + '07_correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 07_correlation_matrix.png\")"
      ],
      "metadata": {
        "id": "1QsSPINQSlFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifikasi highly correlated pairs (potential multicollinearity)\n",
        "print(\"\\nðŸ” HIGHLY CORRELATED VARIABLE PAIRS:\")\n",
        "print(\"=\"*70)\n",
        "print(\"(|r| > 0.7)\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "high_corr_pairs = []\n",
        "\n",
        "for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "        corr_value = corr_matrix.iloc[i, j]\n",
        "        if abs(corr_value) > 0.7:\n",
        "            high_corr_pairs.append({\n",
        "                'Variable_1': corr_matrix.columns[i],\n",
        "                'Variable_2': corr_matrix.columns[j],\n",
        "                'Correlation': corr_value\n",
        "            })\n",
        "\n",
        "if high_corr_pairs:\n",
        "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlation', ascending=False)\n",
        "    print(high_corr_df.to_string(index=False))\n",
        "    high_corr_df.to_csv(FIGURES_PATH +'high_correlation_pairs.csv', index=False)\n",
        "    print(\"\\nSaved: high_correlation_pairs.csv\")\n",
        "else:\n",
        "    print(\"Tidak ada pasangan variabel dengan korelasi tinggi (|r| > 0.7)\")"
      ],
      "metadata": {
        "id": "ShL8_uBuSyQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ðŸ’¡ Key Insight #2: Multicollinearity\n",
        "\n",
        "**Multicollinearity** terjadi ketika variabel predictor sangat berkorelasi satu sama lain.\n",
        "\n",
        "**Dampak**:\n",
        "- Membuat model sulit mengidentifikasi efek individual setiap variabel\n",
        "- Coefficient estimates menjadi tidak stabil\n",
        "- Standard errors meningkat\n",
        "\n",
        "**Solusi**:\n",
        "1. Remove salah satu variabel dari pasangan yang highly correlated\n",
        "2. Combine kedua variabel (feature engineering)\n",
        "3. Use dimensionality reduction (PCA)\n",
        "4. Use regularization (Lasso, Ridge)"
      ],
      "metadata": {
        "id": "2QNvUsLgS8RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot matrix untuk variabel dengan correlation tinggi (sampling untuk efisiensi)\n",
        "# Pilih subset variabel yang menarik\n",
        "interesting_vars = ['age', 'duration', 'campaign', 'previous', 'euribor3m', 'nr.employed']\n",
        "sample_size = min(1000, len(df))  # Sample untuk efisiensi plotting\n",
        "\n",
        "sampled_df = df[interesting_vars].sample(n=sample_size, random_state=42)\n",
        "\n",
        "# Create pair plot\n",
        "pairplot = sns.pairplot(sampled_df, diag_kind='kde', plot_kws={'alpha': 0.6, 's': 20})\n",
        "pairplot.fig.suptitle('Pair Plot - Selected Numerical Variables (Sample)',\n",
        "                       y=1.01, fontsize=16, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH +'08_pairplot_selected_vars.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 08_pairplot_selected_vars.png\")"
      ],
      "metadata": {
        "id": "kOEtyjx5S4Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "ðŸŽ¨ PERTEMUAN 3: INSIGHTS & PREPARATION\n",
        "---\n",
        "\n",
        "\n",
        "# 3.1 FEATURE ENGINEERING\n",
        "\n",
        "**Feature Engineering** = proses membuat fitur baru dari fitur yang sudah ada untuk meningkatkan performa model.\n",
        "\n",
        "Kita akan buat beberapa features baru berdasarkan domain knowledge dan EDA findings."
      ],
      "metadata": {
        "id": "ZZy5zZ62Tjrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Age groups (demographic segmentation)\n",
        "df['age_group'] = pd.cut(df['age'],\n",
        "                         bins=[0, 25, 35, 45, 55, 65, 100],\n",
        "                         labels=['<25', '25-35', '36-45', '46-55', '56-65', '65+'])\n",
        "\n",
        "print(\"Feature created: age_group\")\n",
        "print(df['age_group'].value_counts().sort_index())"
      ],
      "metadata": {
        "id": "kYU_w0eJTGuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Contact frequency category (effort dalam kampanye)\n",
        "df['campaign_intensity'] = pd.cut(df['campaign'],\n",
        "                                   bins=[0, 1, 3, 5, 100],\n",
        "                                   labels=['Low (1)', 'Medium (2-3)', 'High (4-5)', 'Very High (6+)'])\n",
        "\n",
        "print(\"\\nFeature created: campaign_intensity\")\n",
        "print(df['campaign_intensity'].value_counts().sort_index())\n"
      ],
      "metadata": {
        "id": "W590lX9GUdpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Previous contact success rate (bagi yang pernah dikontak)\n",
        "# Note: hanya applicable untuk yang was_contacted_before = 1\n",
        "df['prev_success_rate'] = 0.0\n",
        "mask = df['previous'] > 0\n",
        "df.loc[mask, 'prev_success_rate'] = (df.loc[mask, 'poutcome'] == 'success').astype(int)\n",
        "\n",
        "print(\"\\nFeature created: prev_success_rate\")\n",
        "print(f\"   Previous contacts with success: {(df['prev_success_rate'] == 1).sum()}\")"
      ],
      "metadata": {
        "id": "7cIAdAM9UgAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Economic indicator composite (dimensionality reduction manual)\n",
        "# Normalize dulu, lalu combine\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "economic_vars = ['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
        "scaler = StandardScaler()\n",
        "df[economic_vars] = scaler.fit_transform(df[economic_vars])\n",
        "\n",
        "# Create composite score (weighted average atau simple average)\n",
        "df['economic_score'] = df[economic_vars].mean(axis=1)\n",
        "\n",
        "print(\"\\nFeature created: economic_score (composite of economic indicators)\")\n",
        "print(f\"   Mean: {df['economic_score'].mean():.2f}, Std: {df['economic_score'].std():.2f}\")"
      ],
      "metadata": {
        "id": "pN26HCyeUiiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Contact duration categories (proxy untuk interest level)\n",
        "df['duration_category'] = pd.cut(df['duration'],\n",
        "                                 bins=[0, 60, 180, 300, 1000000],\n",
        "                                 labels=['Very Short (<1min)', 'Short (1-3min)',\n",
        "                                        'Medium (3-5min)', 'Long (>5min)'])\n",
        "\n",
        "print(\"\\nFeature created: duration_category\")\n",
        "print(df['duration_category'].value_counts().sort_index())"
      ],
      "metadata": {
        "id": "1ru_S_7MUlg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTANT NOTE: Duration Variable\n",
        "\n",
        "Variabel `duration` sangat predictive (call duration panjang = likely subscribe).\n",
        "\n",
        "**TAPI**: Duration hanya diketahui SETELAH call selesai!\n",
        "\n",
        "**Untuk Realistic Predictive Model**:\n",
        "- Duration TIDAK boleh digunakan sebagai predictor\n",
        "- Kita hanya pakai untuk EDA dan understanding\n",
        "- Nanti di modeling, kita akan exclude duration\n",
        "\n",
        "Ini adalah contoh **data leakage** yang harus dihindari."
      ],
      "metadata": {
        "id": "3vz7f3yvWk06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Season/Quarter dari month\n",
        "season_map = {\n",
        "    'mar': 'Q1', 'apr': 'Q1', 'may': 'Q1',\n",
        "    'jun': 'Q2', 'jul': 'Q2', 'aug': 'Q2',\n",
        "    'sep': 'Q3', 'oct': 'Q3', 'nov': 'Q3',\n",
        "    'dec': 'Q4', 'jan': 'Q4', 'feb': 'Q4'\n",
        "}\n",
        "df['quarter'] = df['month'].map(season_map)\n",
        "\n",
        "print(\"\\nFeature created: quarter\")\n",
        "print(df['quarter'].value_counts().sort_index())"
      ],
      "metadata": {
        "id": "-FAGd6_3WgGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Binary flags untuk interpretability\n",
        "df['has_default'] = (df['default'] == 'yes').astype(int)\n",
        "df['has_housing_loan'] = (df['housing'] == 'yes').astype(int)\n",
        "df['has_personal_loan'] = (df['loan'] == 'yes').astype(int)\n",
        "df['is_married'] = (df['marital'] == 'married').astype(int)\n",
        "\n",
        "print(\"\\nBinary features created:\")\n",
        "print(f\"   - has_default: {df['has_default'].sum()} ({100*df['has_default'].mean():.2f}%)\")\n",
        "print(f\"   - has_housing_loan: {df['has_housing_loan'].sum()} ({100*df['has_housing_loan'].mean():.2f}%)\")\n",
        "print(f\"   - has_personal_loan: {df['has_personal_loan'].sum()} ({100*df['has_personal_loan'].mean():.2f}%)\")\n",
        "print(f\"   - is_married: {df['is_married'].sum()} ({100*df['is_married'].mean():.2f}%)\")"
      ],
      "metadata": {
        "id": "qbQWQY6TWq92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.2 VISUAL STORYTELLING\n",
        "\n",
        "Sekarang kita buat visualisasi yang **menceritakan story** berdasarkan findings kita."
      ],
      "metadata": {
        "id": "ogIzIbW9WwWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Story 1: Age & Job profile dari subscribers vs non-subscribers\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Age distribution by target\n",
        "for target_val in ['no', 'yes']:\n",
        "    subset = df[df['y'] == target_val]['age']\n",
        "    axes[0, 0].hist(subset, bins=30, alpha=0.6, label=f'Subscribed: {target_val}', edgecolor='black')\n",
        "\n",
        "axes[0, 0].set_title('Age Distribution by Subscription Status', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Age')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Age group success rate\n",
        "age_group_rate = df.groupby('age_group')['y'].apply(lambda x: (x == 'yes').mean() * 100).sort_index()\n",
        "age_group_rate.plot(kind='bar', ax=axes[0, 1], color='teal', edgecolor='black')\n",
        "axes[0, 1].set_title('Subscription Rate by Age Group', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Age Group')\n",
        "axes[0, 1].set_ylabel('Subscription Rate (%)')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "for i, v in enumerate(age_group_rate.values):\n",
        "    axes[0, 1].text(i, v + 0.5, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 3. Top jobs by volume\n",
        "top_jobs = df['job'].value_counts().head(10)\n",
        "top_jobs.plot(kind='barh', ax=axes[1, 0], color='steelblue', edgecolor='black')\n",
        "axes[1, 0].set_title('Top 10 Jobs by Volume', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Count')\n",
        "axes[1, 0].set_ylabel('Job Type')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 4. Job subscription rate (top 10)\n",
        "job_rate = df.groupby('job')['y'].apply(lambda x: (x == 'yes').mean() * 100)\n",
        "job_rate_top = job_rate.sort_values(ascending=False).head(10)\n",
        "job_rate_top.plot(kind='barh', ax=axes[1, 1], color='coral', edgecolor='black')\n",
        "axes[1, 1].set_title('Top 10 Jobs by Subscription Rate', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Subscription Rate (%)')\n",
        "axes[1, 1].set_ylabel('Job Type')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH +'09_story_demographics.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 09_story_demographics.png\")\n"
      ],
      "metadata": {
        "id": "H6k_ne5OWtUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Story 2: Campaign characteristics & effectiveness\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Campaign intensity vs success rate\n",
        "campaign_success = df.groupby('campaign_intensity')['y'].apply(lambda x: (x == 'yes').mean() * 100)\n",
        "campaign_success.plot(kind='bar', ax=axes[0, 0], color='orange', edgecolor='black')\n",
        "axes[0, 0].set_title('Subscription Rate by Campaign Intensity', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Campaign Intensity')\n",
        "axes[0, 0].set_ylabel('Subscription Rate (%)')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "for i, v in enumerate(campaign_success.values):\n",
        "    axes[0, 0].text(i, v + 0.5, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 2. Duration vs subscription (box plot)\n",
        "df.boxplot(column='duration', by='y', ax=axes[0, 1], patch_artist=True)\n",
        "axes[0, 1].set_title('Call Duration by Subscription Status', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Subscribed?')\n",
        "axes[0, 1].set_ylabel('Duration (seconds)')\n",
        "axes[0, 1].get_figure().suptitle('')  # Remove default title\n",
        "\n",
        "# 3. Month performance\n",
        "month_order = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
        "month_rate = df.groupby('month')['y'].apply(lambda x: (x == 'yes').mean() * 100)\n",
        "month_rate = month_rate.reindex(month_order, fill_value=0)\n",
        "month_rate.plot(kind='bar', ax=axes[1, 0], color='purple', edgecolor='black')\n",
        "axes[1, 0].set_title('Subscription Rate by Month', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Month')\n",
        "axes[1, 0].set_ylabel('Subscription Rate (%)')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 4. Previous outcome impact\n",
        "poutcome_rate = df.groupby('poutcome')['y'].apply(lambda x: (x == 'yes').mean() * 100)\n",
        "poutcome_rate.plot(kind='bar', ax=axes[1, 1], color='green', edgecolor='black')\n",
        "axes[1, 1].set_title('Subscription Rate by Previous Campaign Outcome', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Previous Outcome')\n",
        "axes[1, 1].set_ylabel('Subscription Rate (%)')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "for i, v in enumerate(poutcome_rate.values):\n",
        "    axes[1, 1].text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH +'10_story_campaign.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 10_story_campaign.png\")"
      ],
      "metadata": {
        "id": "IrwYeJ62W5FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Story 3: Economic context\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Scatter: euribor vs subscription rate\n",
        "euribor_bins = pd.cut(df['euribor3m'], bins=20)\n",
        "euribor_rate = df.groupby(euribor_bins)['y'].apply(lambda x: (x == 'yes').mean() * 100)\n",
        "euribor_midpoints = [interval.mid for interval in euribor_rate.index]\n",
        "\n",
        "axes[0, 0].scatter(euribor_midpoints, euribor_rate.values, s=100, alpha=0.6, color='red', edgecolor='black')\n",
        "axes[0, 0].plot(euribor_midpoints, euribor_rate.values, color='darkred', linewidth=2, alpha=0.7)\n",
        "axes[0, 0].set_title('Subscription Rate vs Euribor 3M Rate', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Euribor 3M Rate')\n",
        "axes[0, 0].set_ylabel('Subscription Rate (%)')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Employment variation rate\n",
        "emp_bins = pd.cut(df['emp.var.rate'], bins=10)\n",
        "emp_rate = df.groupby(emp_bins)['y'].apply(lambda x: (x == 'yes').mean() * 100)\n",
        "emp_midpoints = [interval.mid for interval in emp_rate.index]\n",
        "\n",
        "axes[0, 1].bar(range(len(emp_rate)), emp_rate.values, color='skyblue', edgecolor='black')\n",
        "axes[0, 1].set_title('Subscription Rate by Employment Variation Rate', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Employment Variation Rate (binned)')\n",
        "axes[0, 1].set_ylabel('Subscription Rate (%)')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 3. Consumer confidence index\n",
        "conf_bins = pd.cut(df['cons.conf.idx'], bins=15)\n",
        "conf_rate = df.groupby(conf_bins)['y'].apply(lambda x: (x == 'yes').mean() * 100)\n",
        "conf_midpoints = [interval.mid for interval in conf_rate.index]\n",
        "\n",
        "axes[1, 0].scatter(conf_midpoints, conf_rate.values, s=100, alpha=0.6, color='green', edgecolor='black')\n",
        "axes[1, 0].plot(conf_midpoints, conf_rate.values, color='darkgreen', linewidth=2, alpha=0.7)\n",
        "axes[1, 0].set_title('Subscription Rate vs Consumer Confidence Index', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Consumer Confidence Index')\n",
        "axes[1, 0].set_ylabel('Subscription Rate (%)')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Economic score distribution by target\n",
        "for target_val in ['no', 'yes']:\n",
        "    subset = df[df['y'] == target_val]['economic_score']\n",
        "    axes[1, 1].hist(subset, bins=30, alpha=0.6, label=f'Subscribed: {target_val}', edgecolor='black')\n",
        "\n",
        "axes[1, 1].set_title('Economic Score Distribution by Subscription Status', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Economic Score (Composite)')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_PATH +'11_story_economic.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: 11_story_economic.png\")"
      ],
      "metadata": {
        "id": "RcNS9f4lXCHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.3 KEY INSIGHTS & BUSINESS RECOMMENDATIONS\n",
        "\n",
        "Berdasarkan analisis komprehensif, berikut adalah key insights:"
      ],
      "metadata": {
        "id": "Ox2NqNP9XLhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY INSIGHTS & FINDINGS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "insights = \"\"\"\n",
        "1. CLASS IMBALANCE\n",
        "   - Hanya ~11% nasabah yang subscribe term deposit\n",
        "   - Ini adalah typical challenge dalam marketing campaign\n",
        "   - Recommendation: Use appropriate evaluation metrics (F1, AUC-ROC, not just accuracy)\n",
        "\n",
        "2. DEMOGRAPHIC PATTERNS\n",
        "   - Age: Nasabah berusia 56-65 tahun memiliki conversion rate tertinggi\n",
        "   - Job: Students dan retired people lebih likely subscribe\n",
        "   - Education: Nasabah dengan pendidikan tinggi cenderung lebih tertarik\n",
        "   - Recommendation: Target segmen senior dan high-education background\n",
        "\n",
        "3. CAMPAIGN CHARACTERISTICS\n",
        "   - Duration: SANGAT predictive (tapi tidak boleh dipakai untuk prediction!)\n",
        "   - Campaign intensity: Less is more - terlalu banyak contact menurunkan success rate\n",
        "   - Previous success: Jika previous campaign success, jauh lebih likely subscribe lagi\n",
        "   - Recommendation: Focus pada quality over quantity, follow-up previous success\n",
        "\n",
        "4. TEMPORAL PATTERNS\n",
        "   - Month: Maret, September, Oktober, Desember memiliki success rate lebih tinggi\n",
        "   - Day of week: Tidak ada perbedaan signifikan\n",
        "   - Recommendation: Time campaign di bulan-bulan dengan conversion rate tinggi\n",
        "\n",
        "5. ECONOMIC INDICATORS\n",
        "   - Strong correlation antara economic indicators dengan subscription\n",
        "   - Euribor rate: Negative correlation dengan subscription (higher rate = lower subscription)\n",
        "   - Employment variation: Negative correlation\n",
        "   - Recommendation: Consider macroeconomic conditions dalam campaign planning\n",
        "\n",
        "6. MULTICOLLINEARITY CONCERN\n",
        "   - Economic indicators sangat correlated satu sama lain\n",
        "   - Feature engineering (economic_score) dapat help reduce dimensionality\n",
        "   - Recommendation: Consider regularization atau dimensionality reduction\n",
        "\n",
        "7. CONTACT METHOD\n",
        "   - Cellular contact lebih efektif dibanding telephone\n",
        "   - Recommendation: Prioritize cellular contact method\n",
        "\n",
        "8. LOAN STATUS\n",
        "   - Nasabah dengan personal loan atau housing loan slightly less likely subscribe\n",
        "   - Default history: Very few cases, tapi sangat negative impact\n",
        "   - Recommendation: Screen for financial stability\n",
        "\n",
        "KEY VARIABLES FOR MODELING (berdasarkan statistical tests):\n",
        "   HIGHEST IMPACT:\n",
        "   - duration (exclude for realistic model!)\n",
        "   - poutcome (previous campaign outcome)\n",
        "   - euribor3m (economic indicator)\n",
        "   - nr.employed (economic indicator)\n",
        "   - month (temporal)\n",
        "\n",
        "   MODERATE IMPACT:\n",
        "   - age, job, education\n",
        "   - contact method\n",
        "   - campaign intensity\n",
        "\"\"\"\n",
        "\n",
        "print(insights)\n",
        "\n",
        "# Save insights to text file\n",
        "with open(FIGURES_PATH + 'key_insights.txt', 'w') as f:\n",
        "    f.write(insights)\n",
        "\n",
        "print(\"\\nSaved: key_insights.txt\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "lD5DB0ZJXIL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 DATA PREPARATION FOR MODELING\n",
        "\n",
        "Sekarang kita prepare data yang clean dan ready untuk modeling.\n"
      ],
      "metadata": {
        "id": "-E7L4QeRXSYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create final dataset untuk modeling\n",
        "df_clean = df.copy()\n",
        "\n",
        "print(\"\\nDATA PREPARATION FOR MODELING:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Encode target variable\n",
        "df_clean['target'] = (df_clean['y'] == 'yes').astype(int)\n",
        "print(f\"Target encoded: yes=1, no=0\")\n",
        "\n",
        "# 2. Handle unknown values dalam kategorikal\n",
        "# Strategy: Treat 'unknown' sebagai kategori tersendiri (for now)\n",
        "# Alternative: Impute dengan mode atau build imputation model\n",
        "print(f\"\\nUnknown values kept as separate category (for now)\")\n",
        "\n",
        "# 3. List features untuk modeling (exclude duration untuk realistic model)\n",
        "features_to_use = [\n",
        "    # Demographic\n",
        "    'age', 'job', 'marital', 'education',\n",
        "    # Financial\n",
        "    'default', 'housing', 'loan',\n",
        "    'has_default', 'has_housing_loan', 'has_personal_loan',\n",
        "    # Campaign\n",
        "    'contact', 'month', 'day_of_week', 'campaign',\n",
        "    # Previous campaign\n",
        "    'pdays', 'previous', 'poutcome', 'was_contacted_before',\n",
        "    # Economic\n",
        "    'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed',\n",
        "    'economic_score',\n",
        "    # Engineered features\n",
        "    'age_group', 'campaign_intensity', 'quarter', 'is_married'\n",
        "]\n",
        "\n",
        "print(f\"\\nFeatures selected for modeling: {len(features_to_use)}\")\n",
        "\n",
        "# 4. Separate features and target\n",
        "X = df_clean[features_to_use].copy()\n",
        "y = df_clean['target'].copy()\n",
        "\n",
        "print(f\"\\nFeatures (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "\n",
        "# 5. Identify column types for encoding later\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(f\"\\nNumerical features: {len(numerical_features)}\")\n",
        "print(f\"Categorical features: {len(categorical_features)}\")"
      ],
      "metadata": {
        "id": "2WDktaqIXPGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Catatan untuk File Modeling (File 2):\n",
        "\n",
        "**Yang perlu dilakukan di File 2:**\n",
        "1. **Encoding categorical variables**:\n",
        "   - One-Hot Encoding untuk nominal variables\n",
        "   - Label/Ordinal Encoding untuk ordinal variables\n",
        "   - Consider target encoding untuk high-cardinality variables\n",
        "\n",
        "2. **Feature scaling**:\n",
        "   - StandardScaler atau MinMaxScaler untuk numerical features\n",
        "   - Fit pada training set, transform pada test set\n",
        "\n",
        "3. **Train-test split**:\n",
        "   - Stratified split karena class imbalance\n",
        "   - Typical ratio: 70-30 atau 80-20\n",
        "\n",
        "4. **Handle class imbalance**:\n",
        "   - SMOTE (Synthetic Minority Over-sampling)\n",
        "   - Class weights dalam model\n",
        "   - Threshold adjustment\n",
        "\n",
        "5. **Model selection & evaluation**:\n",
        "   - Decision Tree dengan GridSearchCV\n",
        "   - Metrics: F1-score, AUC-ROC, Precision-Recall\n",
        "   - Feature importance analysis\n",
        "   - LIME untuk explainability"
      ],
      "metadata": {
        "id": "6c7bs4nmXZ6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create comprehensive dataset untuk export\n",
        "# Include both original and engineered features\n",
        "\n",
        "# Columns to export\n",
        "export_columns = features_to_use + ['target', 'duration', 'y']  # Include duration untuk reference\n",
        "df_export = df_clean[export_columns].copy()\n",
        "\n",
        "print(\"\\nPREPARING EXPORT:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Dataset shape: {df_export.shape}\")\n",
        "print(f\"Features: {len(features_to_use)}\")\n",
        "print(f\"Target distribution:\")\n",
        "print(df_export['target'].value_counts())\n",
        "print(f\"\\nClass balance: {100*df_export['target'].mean():.2f}% positive class\")"
      ],
      "metadata": {
        "id": "ZIHiz9erXV12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export cleaned dataset\n",
        "df_export.to_csv(BASE_PATH + 'bank_marketing_cleaned.csv', index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPORT COMPLETED!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"ðŸ“ File saved: {BASE_PATH}bank_marketing_cleaned.csv\")\n",
        "print(f\"Rows: {len(df_export):,}\")\n",
        "print(f\"Columns: {len(df_export.columns)}\")\n",
        "print(\"\\nDATASET READY FOR MODELING! ðŸš€\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "a4jGOOgJXdGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 DATA QUALITY REPORT (SUMMARY)"
      ],
      "metadata": {
        "id": "0KnfbzmnXjnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate comprehensive data quality report\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL DATA QUALITY REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "report = f\"\"\"\n",
        "DATASET INFORMATION:\n",
        "- Original rows: {len(df_original):,}\n",
        "- Final rows: {len(df_export):,}\n",
        "- Original columns: {len(df_original.columns)}\n",
        "- Final columns: {len(df_export.columns)}\n",
        "\n",
        "MISSING VALUES:\n",
        "- Original dataset: {df_original.isnull().sum().sum()} missing values\n",
        "- Final dataset: {df_export.isnull().sum().sum()} missing values\n",
        "\n",
        "DUPLICATES:\n",
        "- Duplicate rows removed: 0\n",
        "\n",
        "DATA TYPES:\n",
        "- Numerical features: {len(numerical_features)}\n",
        "- Categorical features: {len(categorical_features)}\n",
        "\n",
        "TARGET VARIABLE:\n",
        "- Positive class (y=1): {(df_export['target']==1).sum():,} ({100*df_export['target'].mean():.2f}%)\n",
        "- Negative class (y=0): {(df_export['target']==0).sum():,} ({100*(1-df_export['target'].mean()):.2f}%)\n",
        "- Class imbalance ratio: 1:{(df_export['target']==0).sum()/(df_export['target']==1).sum():.1f}\n",
        "\n",
        "OUTLIERS:\n",
        "- Variables with outliers: {len(outlier_df[outlier_df['Outliers_Count'].astype(str).str.replace('%','').astype(float) > 0])}\n",
        "- See outlier_summary.csv for details\n",
        "\n",
        "FEATURE ENGINEERING:\n",
        "- Original features: {len(df_original.columns)}\n",
        "- Engineered features: {len(df_export.columns) - len(df_original.columns)}\n",
        "- New features: age_group, campaign_intensity, economic_score, duration_category,\n",
        "                quarter, was_contacted_before, has_default, has_housing_loan,\n",
        "                has_personal_loan, is_married, target\n",
        "\n",
        "STATISTICAL TESTS PERFORMED:\n",
        "- T-tests (numerical vs target): {len(ttest_df)}\n",
        "- Chi-square tests (categorical vs target): {len(chisq_df)}\n",
        "- Correlation analysis: Completed\n",
        "\n",
        "EXPORTED FILES:\n",
        "1. bank_marketing_cleaned.csv (main dataset for modeling)\n",
        "2. All figures saved to ./figures/ directory\n",
        "3. Statistical test results (CSV)\n",
        "4. Descriptive statistics (CSV)\n",
        "5. Key insights (TXT)\n",
        "\n",
        "RECOMMENDATIONS FOR MODELING:\n",
        "1. Address class imbalance (SMOTE, class weights, or threshold tuning)\n",
        "2. Exclude 'duration' for realistic predictive model\n",
        "3. Use stratified train-test split\n",
        "4. Apply appropriate encoding for categorical variables\n",
        "5. Scale numerical features\n",
        "6. Consider regularization due to multicollinearity in economic indicators\n",
        "7. Use appropriate evaluation metrics (F1, AUC-ROC, Precision-Recall)\n",
        "8. Perform feature selection based on importance\n",
        "9. Cross-validation for robust evaluation\n",
        "10. Document model assumptions and limitations\n",
        "\n",
        "NEXT STEPS (FILE 2 - MODELING):\n",
        "â†’ Load bank_marketing_cleaned.csv\n",
        "â†’ Encode categorical variables\n",
        "â†’ Scale numerical features\n",
        "â†’ Train-test split (stratified)\n",
        "â†’ Handle class imbalance\n",
        "â†’ Build Decision Tree with GridSearchCV\n",
        "â†’ Evaluate with multiple metrics\n",
        "â†’ Feature importance analysis\n",
        "â†’ Explainability with LIME\n",
        "â†’ Model interpretation & business insights\n",
        "\"\"\"\n",
        "\n",
        "print(report)\n",
        "\n",
        "# Save report\n",
        "with open(FIGURES_PATH + 'data_quality_report.txt', 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"\\nSaved: data_quality_report.txt\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "WjKJqcfeXfmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "TUTORIAL COMPLETED!\n",
        "---\n",
        "\n",
        "#ðŸ“š What You've Learned:\n",
        "\n",
        "##**Pertemuan 1: Foundation**\n",
        "Data loading dan initial exploration  \n",
        "Data quality assessment (missing values, duplicates, data types)  \n",
        "Data cleaning dan basic transformation  \n",
        "Descriptive statistics (mean, median, std, quartiles, skewness, kurtosis)  \n",
        "Understanding target variable distribution  \n",
        "\n",
        "##**Pertemuan 2: Deep Exploration**\n",
        "Univariate analysis (distributions, outliers dengan IQR method)  \n",
        "Bivariate analysis (numerical vs target, categorical vs target)  \n",
        "Statistical hypothesis testing (t-test, chi-square test)  \n",
        "Effect size interpretation (Cohen's d, CramÃ©r's V)  \n",
        "Correlation analysis dan multicollinearity detection  \n",
        "Multivariate patterns dengan pair plots  \n",
        "\n",
        "##**Pertemuan 3: Insights & Preparation**\n",
        "Feature engineering (binning, composite features, binary flags)  \n",
        "Visual storytelling dengan meaningful plots  \n",
        "Business insights generation  \n",
        "Data preparation untuk modeling  \n",
        "Comprehensive data quality reporting  \n",
        "\n",
        "#Key Takeaways:\n",
        "\n",
        "1. **EDA is iterative** - Terus explore sampai punya deep understanding\n",
        "2. **Statistik â‰  ML** - Statistik untuk understanding, ML untuk prediction\n",
        "3. **Context matters** - Business knowledge sama pentingnya dengan technical skills\n",
        "4. **Data quality first** - Garbage in, garbage out\n",
        "5. **Visual storytelling** - Plot yang baik worth a thousand words\n",
        "6. **Feature engineering** - Domain knowledge dapat boost model performance significantly\n",
        "7. **Document everything** - Reproducibility dan transparency are crucial\n",
        "\n",
        "#ðŸ“– Recommended Next Steps:\n",
        "\n",
        "1. **Practice**: Coba dataset lain dengan domain berbeda\n",
        "2. **Deepen statistics**: Belajar lebih dalam tentang inferential statistics\n",
        "3. **Advanced visualization**: Explore plotly, altair untuk interactive viz\n",
        "4. **Feature selection**: Learn about LASSO, RFE, feature importance\n",
        "5. **Ready for modeling**: Move to File 2 untuk classification modeling!\n",
        "\n",
        "#ðŸ’¡ Pro Tips untuk Tugas Akhir:\n",
        "\n",
        "- **Start with good EDA**: Pahami data dulu sebelum modeling\n",
        "- **Document as you go**: Jangan tunggu sampai selesai\n",
        "- **Tell a story**: Connect findings dengan research questions\n",
        "- **Be critical**: Question assumptions, validate findings\n",
        "- **Iterate**: EDA bukan one-time process\n",
        "- **Communicate clearly**: Technical correctness + clear communication = excellent thesis\n",
        "\n",
        "---\n",
        "\n",
        "#ðŸš€ READY FOR MODELING!\n",
        "\n",
        "Dataset sudah clean, features sudah engineered, insights sudah digali.  \n",
        "**Next**: Build robust classification model dengan Decision Tree, GridSearch, dan LIME!\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck dengan pembelajaran dan tugas akhir! ðŸ’ª**"
      ],
      "metadata": {
        "id": "gf4-FyqvXubY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final check: Display first few rows of cleaned dataset\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREVIEW: bank_marketing_cleaned.csv\")\n",
        "print(\"=\"*80)\n",
        "print(df_export.head(10))\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"END OF EDA TUTORIAL\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "YwFy0fihXmdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDQf3pixXxTO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}